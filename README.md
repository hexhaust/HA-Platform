# HA Platform â€” Multiâ€‘Region, Activeâ€‘Active Kubernetes (AWS â€¢ GCP â€¢ Azure)

Productionâ€‘grade **reference platform** for running apps across **multiple regions** and **multiple clouds** with **activeâ€‘active traffic** and **progressive delivery**: **canary**, **blue/green**, and **rolling**.
Built around **Kubernetes**, **Argo Rollouts**, **Ingressâ€‘NGINX**, **ExternalDNS**, **certâ€‘manager**, and a minimal **Prometheus/Grafana + OpenTelemetry** stack.

> âš ï¸ This is a **reference**. Youâ€™ll need to plug in your cloud project/account IDs, IAM/roles, networking/CNI, TLS issuers, and DNS zone. Cloud resources cost moneyâ€”destroy what you donâ€™t need.

---

## Features

* ðŸŒ **Multiâ€‘region, multiâ€‘cloud:** EKS (AWS), GKE (GCP), AKS (Azure)
* â™»ï¸ **Activeâ€‘active traffic:** serve from multiple regions at once; steer via **weighted or latencyâ€‘based DNS**
* ðŸš¦ **Progressive delivery:** Canary & Blue/Green (via **Argo Rollouts**) + standard Rolling (native Kubernetes)
* â˜¸ï¸ **K8s addâ€‘ons:** Ingressâ€‘NGINX, ExternalDNS, certâ€‘manager, optional Gateway API
* ðŸ”­ **Observability:** Prometheus + Grafana (lightweight), OpenTelemetry Collector (export to your backend)
* ðŸ”’ **Security:** TLS by default (via certâ€‘manager), namespaced RBAC, image provenance hooks (stub)

---

## Architecture (ASCII, no Mermaid)

```
Clients â”€â”€> Global DNS (weighted/latency) â”€â”€> Cloud LB â”€â”€> Ingressâ€‘NGINX â”€â”€> Services
                                                    â”‚
                                             Argo Rollouts
                                              (canary/blueâ€‘green)
```

* **Global DNS**: Route 53 / Cloud DNS / Azure DNS with healthâ€‘checked **weighted or latency** routing
* **Ingress**: **Ingressâ€‘NGINX** (same config on EKS/GKE/AKS)
* **Traffic shifts**: Argo Rollouts updates NGINX routing to send % of traffic to canary/preview
* **State**: Prefer **managed DBs per region** with replication; avoid crossâ€‘region StatefulSets for hot paths

---

## Repository layout

```
ha-platform/
â”œâ”€ README.md
â”œâ”€ LICENSE
â”œâ”€ CONTRIBUTING.md
â”œâ”€ .gitignore
â”œâ”€ docs/
â”‚  â”œâ”€ architecture.md
â”‚  â”œâ”€ deploy-strategies.md
â”‚  â”œâ”€ operations.md
â”‚  â”œâ”€ security.md
â”‚  â””â”€ observability.md
â”œâ”€ apps/
â”‚  â””â”€ hello/                 # sample service with 3 deployment styles
â”‚     â”œâ”€ kustomization.yaml
â”‚     â”œâ”€ namespace.yaml
â”‚     â”œâ”€ service.yaml        # stable/canary/preview services (see NOTE below on ports)
â”‚     â”œâ”€ deployment-rolling.yaml
â”‚     â”œâ”€ rollout-canary.yaml
â”‚     â”œâ”€ rollout-bluegreen.yaml
â”‚     â”œâ”€ ingress.yaml        # stable ingress; Rollouts adds canary ingress dynamically
â”‚     â””â”€ httproute.yaml      # (optional) Gateway API example
â”œâ”€ cluster-addons/
â”‚  â”œâ”€ base/
â”‚  â”œâ”€ argo-rollouts/
â”‚  â”œâ”€ ingress-nginx/
â”‚  â”œâ”€ gateway-api/           # optional
â”‚  â”œâ”€ cert-manager/
â”‚  â”œâ”€ external-dns/
â”‚  â”œâ”€ monitoring/
â”‚  â””â”€ opentelemetry/
â”œâ”€ environments/
â”‚  â”œâ”€ aws/us-east-1/cluster/terraform
â”‚  â”œâ”€ aws/eu-west-1/cluster/terraform
â”‚  â”œâ”€ gcp/us-central1/cluster/terraform
â”‚  â””â”€ azure/eastus/cluster/terraform
â”œâ”€ modules/
â”‚  â”œâ”€ eks/  gke/  aks/       # simplified cluster modules
â”‚  â””â”€ global-dns/            # stubs for cross-region weighted records
â”œâ”€ .github/workflows/
â”‚  â”œâ”€ validate.yml
â”‚  â””â”€ deploy.yml             # GitOps/manual stub
â””â”€ tools/scripts/
   â”œâ”€ bootstrap-cluster.sh
   â”œâ”€ install-addons.sh
   â”œâ”€ deploy-hello.sh
   â””â”€ smoke-test.sh
```

> **Port NOTE (important):** The sample container `ghcr.io/nginxdemos/hello:plain-text` listens on **port 80**.
> Make sure `apps/hello/service.yaml`â€™s `targetPort` matches **80** (not 8080). If yours says `8080`, switch to `80`.

---

## Prerequisites

* **CLI:** Terraform â‰¥ 1.6, kubectl â‰¥ 1.28, kustomize â‰¥ 5, Helm â‰¥ 3.12
* **Cloud CLIs:** `aws`, `gcloud`, `az` (authenticated & set to your projects/accounts/subscriptions)
* **DNS:** A zone you control (e.g., `example.com`)
* **Access:** IAM/roles to create clusters, networking, and LBs in your clouds

---

## Quick start (one region first)

> Start with **one cloud/region** to prove the flow. Repeat for others once stable.

1. **Create a cluster** (example: AWS usâ€‘eastâ€‘1):

```bash
cd environments/aws/us-east-1/cluster/terraform
terraform init
terraform apply
# Use the kubeconfig command from outputs, e.g.:
aws eks update-kubeconfig --region us-east-1 --name ha-eks-us-east-1
```

*(GCP: `gcloud container clusters get-credentials ...`; Azure: `az aks get-credentials ...` â€” see module outputs.)*

2. **Install addâ€‘ons** (Ingressâ€‘NGINX, Argo Rollouts, Prom/Grafana, OTel, certâ€‘manager):

```bash
export KUBECONFIG=~/.kube/config   # or your kubeconfig path
bash tools/scripts/bootstrap-cluster.sh
```

3. **ExternalDNS** (pick the right values file for your cloud):

```bash
# AWS example; change the -f to values-gcp.yaml or values-azure.yaml as needed
bash tools/scripts/install-addons.sh
```

4. **TLS** (required): configure a certâ€‘manager Issuer/ClusterIssuer for your DNS (ACME HTTPâ€‘01 or DNSâ€‘01).
   Add your issuer manifests under `cluster-addons/cert-manager/` (not included outâ€‘ofâ€‘box).

5. **Deploy the sample app** with your preferred strategy:

```bash
# rolling | canary | bluegreen
bash tools/scripts/deploy-hello.sh canary
```

6. **DNS**: Point `hello.example.com` at the public address/hostname of your ingress controller
   (or let ExternalDNS manage it if you annotated your Ingress with your domain and have the right RBAC/creds).

7. **Smoke test:**

```bash
bash tools/scripts/smoke-test.sh hello.example.com
```

---

## Progressive delivery (how to drive it)

### Rolling

* Uses native `Deployment` (`apps/hello/deployment-rolling.yaml`).
* Zero downtime with `maxSurge=1`, `maxUnavailable=0` (editable per your SLO).

### Canary (Argo Rollouts + NGINX)

* `apps/hello/rollout-canary.yaml` defines steps: **10% â†’ 30% â†’ 60%** with pauses.
* Argo Rollouts manipulates NGINX canary annotations; traffic shifts happen live.
* Observe metrics/logs during pauses; **promote** or **abort** via Argo Rollouts UI/CLI.

### Blue/Green (Argo Rollouts)

* `apps/hello/rollout-bluegreen.yaml` with `activeService` and `previewService`.
* Validate on the **preview** service; **promote** when ready (no midâ€‘percentage states).

> Choose **one** strategy at a time. `apps/hello/kustomization.yaml` includes common resources;
> the `deploy-hello.sh` script then applies the **one** rollout/deployment you pick.

---

## Multiâ€‘region & activeâ€‘active

1. **Replicate clusters** in additional regions/clouds:

   * AWS: copy `environments/aws/us-east-1` â†’ `eu-west-1` (already scaffolded), update variables
   * GCP: add more regions (e.g., `europe-west1`)
   * Azure: add more regions (e.g., `westeurope`)

2. **Install addâ€‘ons** on each cluster (same commands).

3. **Expose the same hostname** (`hello.example.com`) in every region.

   * ExternalDNS can manage perâ€‘region records (e.g., `us-east-1.hello.example.com`)
   * Use **Global DNS** to create **weighted/latency** A/AAAA/CNAME records that point to each regionâ€™s LB
     (see `modules/global-dns/` stubs; or manage these at your DNS provider/registrar).

4. **Health checks + failâ€‘open**: configure DNS health checks to **deâ€‘weight** unhealthy regions automatically.

---

## Observability

* **Prometheus/Grafana**: basic dashboards are included as a ConfigMap stub (replace with your chart/values).
* **OpenTelemetry Collector**: receives OTLP and exports to **logging** by default â€” change the exporter to your backend.
* **Release annotations & SLOs**: annotate releases and wire alerts to **error budgets**, not raw metrics.

See: `docs/observability.md`

---

## Security

* **TLS by default**: Use certâ€‘manager Issuer/ClusterIssuer (ACME HTTPâ€‘01/DNSâ€‘01).
* **Least privilege**: Namespaced RBAC for apps; avoid clusterâ€‘admin outside automation/bootstrap.
* **Supply chain** (stub): image scanning, SBOM, and signing belong in CI; wire your pipeline to enforce these.

See: `docs/security.md`

---

## Operations

* **Health endpoints**: L7 `/healthz` for LB probes; readiness gates on Pods.
* **Rollouts**: Observe metrics during canary pauses; **promote/abort** intentionally.
* **DNS failover**: Weighted or latency policies + health checks deâ€‘weight failing regions.

See: `docs/operations.md`

---

## Provider specifics (notes)

* **AWS/EKS**: Fill in IAM roles, subnets, and VPC IDs in `modules/eks`. Decide on CNI (VPC CNI/Cilium).
* **GCP/GKE**: Set `project` and networking (`network`, `subnetwork`) in `modules/gke`.
* **Azure/AKS**: Provide resource group and identity of the cluster in `modules/aks`.

> The Terraform modules here are **skeletal** to show integration points. In production, pin versions, add remote state, workspaces, and policy checks (OPA/Sentinel).

---

## CI/CD

This template ships with:

* **`.github/workflows/validate.yml`** â€” basic Terraform format and YAML lint
* **`.github/workflows/deploy.yml`** â€” manual stub (expecting **GitOps** or manual `kubectl apply -k`)

Bring your own CI for build, scan, SBOM, and image signing.

---

## Troubleshooting

* **Ingress returns 404**: confirm `ingress-nginx` is Ready and your Ingress `host` matches DNS.
* **Canary has no effect**: check Argo Rollouts controller health and NGINX canary annotations.
* **Service has no endpoints**: ensure **Service `targetPort` = container `containerPort` (80)**.
* **DNS not updating**: verify ExternalDNS creds/RBAC and `domainFilters` in `values-*.yaml`.

---

## Cleanup

Destroy resources in each environment to avoid costs:

```bash
terraform -chdir=environments/aws/us-east-1/cluster/terraform destroy
# repeat for other regions/clouds
```

---

## Contributing & License

* See `CONTRIBUTING.md` for guidelines
* Licensed under **MIT** (see `LICENSE`)

---
